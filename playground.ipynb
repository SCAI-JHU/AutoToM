{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for customized questions\n",
    "story = \"\"\"1 Ella entered the master_bedroom.\n",
    "2 Ava entered the master_bedroom.\n",
    "3 The onion is in the envelope.\n",
    "4 The envelope is in the master_bedroom.\n",
    "5 Ella exited the master_bedroom.\n",
    "6 Ava moved the onion to the box.\n",
    "7 The box is in the master_bedroom.\n",
    "8 Ava exited the master_bedroom.\n",
    "9 Ella entered the hallway.\"\"\"\n",
    "question = \"Where will Ella look for the onion?\"\n",
    "choices = [\"envelope\", \"box\"] # Correct answer is envelope.\n",
    "dataset_name = \"customize\"\n",
    "episode_name = \"customize_0\"\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf_var_name Belief\n",
      "Var results saved to ../results/var/automated_customize_0.csv\n",
      "Extracted actions: ['Ella entered the master bedroom.', 'Ella exited the master bedroom.', 'Ella entered the hallway.']\n",
      "Initial Model proposed:  ['State', 'Observation', 'Belief']\n",
      "Starting from timestep 2\n",
      "\u001b[92mHypotheses proposed for Observation\n",
      "['Ella sees that the onion is in the envelope.']\u001b[0m\n",
      "\u001b[92mHypotheses proposed for Observation\n",
      "['Ella sees that the onion is in the box.']\u001b[0m\n",
      "Node results saved to ../results/node_results/automated_customize_0_back1_reduce1.csv\n",
      "\u001b[92mAfter time 2: Ella's Belief Probs calculated as ['Ella will look for the onion in the envelope.', 'Ella will look for the onion in the box.'], [0.5, 0.5]\u001b[0m\n",
      "Initial Terminate:  False\n",
      "Initial Utility:  -0.6931471805599453\n",
      "\u001b[92mHypotheses proposed for Goal\n",
      "['Ella wants to find the onion.']\u001b[0m\n",
      "\u001b[92mHypotheses proposed for Goal\n",
      "['Ella wants to find the onion.']\u001b[0m\n",
      "Node results saved to ../results/node_results/automated_customize_0_back1_reduce1.csv\n",
      "\u001b[92mAfter time 2: Ella's Belief Probs calculated as ['Ella will look for the onion in the envelope.', 'Ella will look for the onion in the box.'], [0.44336585742334883, 0.5566341425766511]\u001b[0m\n",
      "Model test:  ['State', 'Observation', 'Belief', 'Action', 'Goal']\n",
      "Model test results:  [0.44336585742334883, 0.5566341425766511]\n",
      "Initial Utility:  -0.6931471805599453\n",
      "Utility Experiments:  {'Action': -0.6867185406922802}\n",
      "Starting from timestep 1\n",
      "\u001b[92mAfter time 1: Belief Probs Updated to ['Ella will look for the onion in the envelope.', 'Ella will look for the onion in the box.'], [0.9668476565821607, 0.03315234341783933]\u001b[0m\n",
      "Node results saved to ../results/node_results/automated_customize_0_back1_reduce1.csv\n",
      "\u001b[92mAfter time 2: Ella's Belief Probs calculated as ['Ella will look for the onion in the envelope.', 'Ella will look for the onion in the box.'], [0.9253858286395246, 0.07461417136047549]\u001b[0m\n",
      "Probs results saved to ../results/probs/automated_customize_0.csv\n",
      "Initial Terminate:  True\n",
      "{'Initial model propose': ['State', 'Observation', 'Belief'], 'Assigned models': {2: ['State', 'Observation', 'Belief'], 1: ['State', 'Observation', 'Belief']}}\n"
     ]
    }
   ],
   "source": [
    "from ProbSolver import ProblemSolver, argmax, argmin\n",
    "solver = ProblemSolver(\n",
    "        story=story,\n",
    "        question=question,\n",
    "        choices=choices,\n",
    "        K=1,\n",
    "        assigned_model=[],\n",
    "        model_name=\"automated\",\n",
    "        episode_name=episode_name,\n",
    "        llm=\"gpt-4o\",\n",
    "        verbose=verbose,\n",
    "        dataset_name=dataset_name,\n",
    "        hypo_method=\"guided\",\n",
    "        nested=False,\n",
    "        video_id=None,\n",
    "        answerfunc=argmax,\n",
    "        back_inference=True,\n",
    "        reduce_hypotheses=True,\n",
    "        precomputed_states=None,\n",
    "        precomputed_actions=None,\n",
    "        prev_hyp=None,\n",
    "        no_model_adjustment=False,\n",
    "        recursion_depth=None\n",
    "    )\n",
    "\n",
    "final_probs, model_record = solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['envelope', 'box'] [0.9253858286395246, 0.07461417136047549]\n"
     ]
    }
   ],
   "source": [
    "print(choices, final_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
